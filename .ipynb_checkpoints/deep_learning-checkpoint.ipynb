{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Setup](#Setup)\n",
    "2. [Deep Learning Pipeline](#Machine-Learning-Pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "[Back to Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm,trange\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ROOT_DIR - root directory\n",
    "ROOT_DIR = os.getcwd()+'/'\n",
    "\n",
    "# FEATURE_DIR - directory where feature dataframes are saved\n",
    "DATA_DIR = ROOT_DIR + 'dataframes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = np.loadtxt(DATA_DIR+'X_train.csv',delimiter=',')\n",
    "X_test = np.loadtxt(DATA_DIR+'X_test.csv',delimiter=',')\n",
    "X_val = np.loadtxt(DATA_DIR+'X_val.csv',delimiter=',')\n",
    "\n",
    "y_train = np.loadtxt(DATA_DIR+'y_train.csv',delimiter=',')\n",
    "y_test = np.loadtxt(DATA_DIR+'y_test.csv',delimiter=',')\n",
    "y_val = np.loadtxt(DATA_DIR+'y_val.csv',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scl = StandardScaler().fit(X_train)\n",
    "X_train_scl = scl.transform(X_train)\n",
    "X_test_scl = scl.transform(X_test)\n",
    "X_val_scl = scl.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set = tf.contrib.learn.python.learn.datasets.base.Dataset(data=X_train_scl,target=y_train)\n",
    "test_set = tf.contrib.learn.python.learn.datasets.base.Dataset(data=X_test_scl,target=y_test)\n",
    "val_set = tf.contrib.learn.python.learn.datasets.base.Dataset(data=X_val_scl,target=y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify important validation metrics\n",
    "validation_metrics = {'accuracy': tf.contrib.metrics.streaming_accuracy,\n",
    "                      'precision': tf.contrib.metrics.streaming_precision,\n",
    "                      'recall': tf.contrib.metrics.streaming_recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify that all features have real-value data\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=148)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "monitor_params = {'x':test_set.data,\n",
    "                 'y':test_set.target,\n",
    "                 'every_n_steps':50,\n",
    "                 'metrics':validation_metrics,\n",
    "                 'early_stopping_metric':'loss',\n",
    "                 'early_stopping_metric_minimize':True,\n",
    "                 'early_stopping_rounds':200}\n",
    "\n",
    "clf_params = {'feature_columns':feature_columns,\n",
    "              'hidden_units':[500,500,500],\n",
    "              'n_classes':2,\n",
    "              'activation_fn':tf.nn.relu,\n",
    "              'optimizer':tf.train.RMSPropOptimizer(learning_rate=0.0001),\n",
    "              'dropout':0.5,\n",
    "              'config':tf.contrib.learn.RunConfig(save_checkpoints_secs=1)}\n",
    "\n",
    "fit_params = {'x':train_set.data,\n",
    "              'y':train_set.target,\n",
    "              'steps':10000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def paramSweep(param,vals,start=0,monitor_params=dict(monitor_params),clf_params=dict(clf_params),\n",
    "               fit_params=dict(fit_params)):\n",
    "    \n",
    "    # Initialize Variables\n",
    "    n_clfs = len(vals)\n",
    "    clfs = [None]*n_clfs\n",
    "    monitors = [None]*n_clfs\n",
    "    \n",
    "    print('Sweeping through %d values for \"%s\"'%(n_clfs,param))\n",
    "    \n",
    "    for i in range(n_clfs):\n",
    "       \n",
    "        # Initialize model directory\n",
    "        model_dir = os.path.join('models',param,str(i+start))\n",
    "        \n",
    "        print('\"%s\" = %s'%(param,str(vals[i])))\n",
    "        print('Model saved in \"%s\"'%model_dir)\n",
    "        \n",
    "        # Initialize monitor\n",
    "        monitors[i] = tf.contrib.learn.monitors.ValidationMonitor(**monitor_params)\n",
    "        \n",
    "        # Update parameters\n",
    "        clf_params[param] = vals[i]\n",
    "        clf_params['model_dir'] = model_dir\n",
    "        fit_params['monitors'] = [monitors[i]]\n",
    "\n",
    "        # Initialize classifier\n",
    "        clfs[i] = tf.contrib.learn.DNNClassifier(**clf_params)\n",
    "        \n",
    "        # Train classifier\n",
    "        clfs[i].fit(**fit_params)\n",
    "        \n",
    "        # Test classifier\n",
    "        scores = clfs[i].evaluate(x=test_set.data, y=test_set.target)\n",
    "        print('Accuracy: {0:f}'.format(scores['accuracy']))\n",
    "        print('AUC: {0:f}'.format(scores['auc']))\n",
    "\n",
    "    return clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sweeping through 5 values for \"optimizer\"\n",
      "\"optimizer\" = <tensorflow.python.training.adagrad.AdagradOptimizer object at 0x7f2319d9b810>\n",
      "Model saved in \"models/optimizer/0\"\n",
      "Accuracy: 0.681020\n",
      "AUC: 0.749779\n",
      "\"optimizer\" = <tensorflow.python.training.rmsprop.RMSPropOptimizer object at 0x7f2319d9b850>\n",
      "Model saved in \"models/optimizer/1\"\n",
      "Accuracy: 0.682200\n",
      "AUC: 0.751229\n",
      "\"optimizer\" = <tensorflow.python.training.rmsprop.RMSPropOptimizer object at 0x7f2319d9b990>\n",
      "Model saved in \"models/optimizer/2\"\n",
      "Accuracy: 0.674384\n",
      "AUC: 0.752192\n",
      "\"optimizer\" = <tensorflow.python.training.rmsprop.RMSPropOptimizer object at 0x7f2319d9b910>\n",
      "Model saved in \"models/optimizer/3\"\n",
      "Accuracy: 0.680873\n",
      "AUC: 0.751913\n",
      "\"optimizer\" = <tensorflow.python.training.adam.AdamOptimizer object at 0x7f23174bc390>\n",
      "Model saved in \"models/optimizer/4\"\n",
      "Accuracy: 0.684117\n",
      "AUC: 0.752831\n"
     ]
    }
   ],
   "source": [
    "opt_clfs = paramSweep('optimizer',[tf.train.AdagradOptimizer(learning_rate=0.05),\n",
    "                                   tf.train.RMSPropOptimizer(learning_rate=0.0001),\n",
    "                                   tf.train.RMSPropOptimizer(learning_rate=0.0005),\n",
    "                                   tf.train.RMSPropOptimizer(learning_rate=0.0001,decay=0.5),\n",
    "                                   tf.train.AdamOptimizer(learning_rate=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sweeping through 4 values for \"hidden_units\"\n",
      "\"hidden_units\" = [100]\n",
      "Model saved in \"models/hidden_units/0\"\n",
      "Accuracy: 0.676154\n",
      "AUC: 0.746102\n",
      "\"hidden_units\" = [500]\n",
      "Model saved in \"models/hidden_units/1\"\n",
      "Accuracy: 0.683233\n",
      "AUC: 0.748555\n",
      "\"hidden_units\" = [100, 200, 100]\n",
      "Model saved in \"models/hidden_units/2\"\n",
      "Accuracy: 0.679988\n",
      "AUC: 0.751736\n",
      "\"hidden_units\" = [500, 500, 500]\n",
      "Model saved in \"models/hidden_units/3\"\n",
      "Accuracy: 0.688247\n",
      "AUC: 0.755893\n"
     ]
    }
   ],
   "source": [
    "hidden_unit_clfs = paramSweep('hidden_units',[[100],[500],[100,200,100],[500,500,500]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sweeping through 3 values for \"dropout\"\n",
      "\"dropout\" = 0.25\n",
      "Model saved in \"models/dropout/0\"\n",
      "Accuracy: 0.682053\n",
      "AUC: 0.753058\n",
      "\"dropout\" = 0.5\n",
      "Model saved in \"models/dropout/1\"\n",
      "Accuracy: 0.689279\n",
      "AUC: 0.755312\n",
      "\"dropout\" = 0.75\n",
      "Model saved in \"models/dropout/2\"\n",
      "Accuracy: 0.661702\n",
      "AUC: 0.753494\n"
     ]
    }
   ],
   "source": [
    "dropout_clfs = paramSweep('dropout',[0.25,0.5,0.75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters:\n",
    "* Optimizer - RMSProp/Adam\n",
    "* Hidden Units - [500,500,500]\n",
    "* Dropout: 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Deep NN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
